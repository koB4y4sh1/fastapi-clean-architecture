# Copyright (c) Microsoft. All rights reserved.

import asyncio

from contextlib import AsyncExitStack
from semantic_kernel import Kernel
from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings
from semantic_kernel.functions.kernel_arguments import KernelArguments
from semantic_kernel.contents import ChatHistorySummarizationReducer,FunctionCallContent, FunctionResultContent
from semantic_kernel.contents.chat_message_content import ChatMessageContent

from src.schema.value_object.agent import AgentObject
from src.schema.value_object.azure_openai import AzureOpenAIObject
from src.schema.value_object.plugin import PluginObject
from src.mcp_plugin.create_mcp_pugins import create_mcp_pugins

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
async def handle_intermediate_steps(message: ChatMessageContent) -> None:
    """
    ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã¯ã€ä¸­é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã”ã¨ã«å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€FunctionCallContentã‚„FunctionResultContentã‚’å€‹åˆ¥ã«å‡¦ç†ã§ãã¾ã™ã€‚
    ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ä¸­é–“çš„ãªãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚¹ãƒ†ãƒƒãƒ—ãªã—ã§æœ€çµ‚å¿œç­”ã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚

    Args:
        message (ChatMessageContent): ä¸­é–“ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    
    Returns:
        None
        
    Example:
        >>> message = ChatMessageContent(role="user", content="What can you do?")
        >>> await handle_intermediate_steps(message)
    
    Note:
        - FunctionCallContentã¯ã€é–¢æ•°å‘¼ã³å‡ºã—ã®è©³ç´°ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚
        - FunctionResultContentã¯ã€é–¢æ•°å‘¼ã³å‡ºã—ã®çµæœã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚
    """
    for item in message.items or []:
        if isinstance(item, FunctionCallContent):
            print(f"Function Call:> {item.name} with arguments: {item.arguments}")
        elif isinstance(item, FunctionResultContent):
            print(f"Function Result:> {item.result} for function: {item.name}")
        else:
            print(f"{message.role}: {message.content}")

async def orchestrator(agent_data:AgentObject, ai_model:AzureOpenAIObject, plugins:list[PluginObject]):
    """
    ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼é–¢æ•°ã€‚ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã€ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­å®šã€AIãƒ¢ãƒ‡ãƒ«ã‚’å—ã‘å–ã‚Šã€å¯¾è©±å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•ã™ã‚‹ã€‚

    Args:
        settings (AgentObject): ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­å®šæƒ…å ±ã‚’å«ã‚€è¾æ›¸ã€‚
        ai_model (AzureOpenAIObject): Azure OpenAI ãªã©ã®AIãƒ¢ãƒ‡ãƒ«è¨­å®šã€‚
        plugins (PluginObject): åˆ©ç”¨ã™ã‚‹ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ãƒªã‚¹ãƒˆã€‚

    Returns:
        None

    Note:
        - å¯¾è©±å±¥æ­´ã®è¦ç´„ã‚„ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®åˆæœŸåŒ–ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å—ä»˜ã¨å¿œç­”ã‚’è¡Œã†ã€‚
        - "exit" ã¨å…¥åŠ›ã™ã‚‹ã“ã¨ã§å¯¾è©±ã‚’çµ‚äº†ã§ãã‚‹ã€‚
    """
    REDUCER_MSG_COUNT = 1      # è¦ç´„ã‚’é©ç”¨ã—ãŸå¾Œã«ä¿æŒã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç›®æ¨™æ•°
    REDUCER_THRESHOLD = 0      # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ãŒtarget_countã‚’è¶…éã—ãŸã¨ãã«ã€å±¥æ­´ãŒæ—©æœŸã«å‰Šæ¸›ã•ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã®ãƒãƒƒãƒ•ã‚¡
    AUTO_MESSAGE_SUMMARIZATION = True  # add_message_asuyncã‚’ä½¿ç”¨ã—ã¦æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ãŸå¾Œã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è‡ªå‹•çš„ã«è¦ç´„ã™ã‚‹ã‹ã©ã†ã‹

    service_id = "orchestrator"
    
    # ã‚«ãƒ¼ãƒãƒ«ä½œæˆ
    kernel = Kernel()

    # Kernelã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’ç™»éŒ²
    kernel.add_service(AzureChatCompletion(service_id=service_id))

    # AzureChatCompletionã®è¨­å®š
    # settings = AzureChatPromptExecutionSettings(**agent_data.model.options.model_dict())
    settings = AzureChatPromptExecutionSettings(
        temperature=agent_data.model.options.temperature,
        max_tokens=agent_data.model.options.max_tokens,
        top_p=agent_data.model.options.top_p,
        response_format=agent_data.model.options.response_format,
    )

    # è¦ç´„ãƒªãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ
    history_summarization_reducer = ChatHistorySummarizationReducer(
        service=AzureChatCompletion(), 
        target_count=REDUCER_MSG_COUNT, 
        threshold_count=REDUCER_THRESHOLD,
        auto_reduce=AUTO_MESSAGE_SUMMARIZATION,
        use_single_summary=False,
        include_function_content_in_summary=True,
    )
    
    # å‰å›ã¾ã§ã®ä¼šè©±ã®è¦ç´„ã‚’è¿½åŠ 
    history_summarization_reducer.add_assistant_message("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ—¥æœ¬èªã§æŒ¨æ‹¶ã—ã€AIã®èƒ½åŠ›ã«ã¤ã„ã¦å°‹ã­ãŸå¾Œã€è¦³å…‰åœ°ã«é–¢ã™ã‚‹è©³ç´°ã‚’æ±‚ã‚ã¾ã—ãŸã€‚AIã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›ã™ã‚‹è¦³å…‰åœ°ã«æ²¿ã£ãŸæƒ…å ±æä¾›ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å…·ä½“çš„ã«æ—¥æœ¬ã®äº¬éƒ½ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¾ã—ãŸã€‚")
    
    # MCPãƒ—ãƒ©ã‚°ã‚¤ãƒ³(stdio transport)ã‚’ä½œæˆ
    mcp_plugins = await create_mcp_pugins(
        plugins, ai_model
    )
    
    async with AsyncExitStack() as stack:
        # MCPãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã¨ã—ã¦ç™»éŒ²
        agent_instances = []
        for mcp_plugin in mcp_plugins:
            instance = await stack.enter_async_context(mcp_plugin)
            agent_instances.append(instance)

        # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ã‚«ãƒ¼ãƒãƒ«ã«è¿½åŠ 
        kernel.add_plugins(agent_instances)
        
        

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆï¼ˆcreate_from_dictã§ã¯model.options.settingsã«AzureChatPromptExecutionSettingsã®æƒ…å ±ã‚’æ¸¡ã™å¿…è¦ãŒã‚ã‚‹ï¼‰
        # agent: ChatCompletionAgent = await AgentRegistry.create_from_dict(
        #         agent_data.to_dict(), kernel=kernel, service=AzureChatCompletion(
        #             api_key=ai_model.api_key, 
        #             endpoint=ai_model.endpoint, 
        #             deployment_name=ai_model.deployment_name
        #         ),
        # )

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆï¼ˆï¼‰
        agent = ChatCompletionAgent(
            kernel=kernel,
            service=AzureChatCompletion(
                api_key=ai_model.api_key,
                endpoint=ai_model.endpoint,
                deployment_name=ai_model.deployment_name
            ),
            arguments=KernelArguments(settings),
        )

        # 2. ä¼šè©±ã‚’ä¿æŒã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä½œæˆ
        # ã‚¹ãƒ¬ãƒƒãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯æ–°ã—ãä½œæˆã•ã‚Œã€
        # æœ€åˆã®å¿œç­”ã¨ã¨ã‚‚ã«è¿”ã•ã‚Œã¾ã™
        thread: ChatHistoryAgentThread = ChatHistoryAgentThread(chat_history=history_summarization_reducer)
        while True:
            user_input = input("User: ")
            if user_input.lower() == "exit":
                break
            # 3. Invoke the agent for a response
            async for response in agent.invoke(messages=user_input, thread=thread, on_intermediate_message=handle_intermediate_steps):
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å†…å®¹ã‚’å‡ºåŠ›
                print(f"Response content:\n{response.message.content}")
                # try:
                #     # JSON ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¤œè¨¼
                #     reasoned_result = StructuredResult.model_validate(json.loads(response.message.content))
                #     print(f"# {response.name}:\n\n{reasoned_result.model_dump_json(indent=4)}")
                # except json.JSONDecodeError as e:
                #     print(f"JSONDecodeError: {e}")
                #     print("Response content is not valid JSON.")
                thread = response.thread

            # Attempt reduction
            # target_countã¯0ã«ã§ããšã€ãã®ã¾ã¾ã§ã¯AIã®å›ç­”ã‚’è¦ç´„ã«å«ã‚ã‚‹ã“ã¨ã¯ã§ããªã„
            is_reduced = await thread.reduce()
            print(f"@ Message Count: {len(thread)}\n")
            if is_reduced:
                print(f"@ History reduced to {len(thread)} messages.")
                    # If reduced, print summary if present    
                async for msg in thread.get_messages():
                    if msg.metadata and msg.metadata.get("__summary__"):
                        print(f"\tSummary: {msg.content}")
                        break

        # 4. Cleanup: ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’å‰Šé™¤
        await thread.delete() if thread else None
    


"""
User: ã‚ãªãŸãŒã§ãã‚‹ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
# PersonalAssistant: ç§ã¯ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã®äºˆç´„ã‚„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«é–¢ã™ã‚‹è³ªå•ã¸ã®å›ç­”ã€è¨ˆç®—ã®ã‚µãƒãƒ¼ãƒˆã€ãŠã‚ˆã³ç¾åœ¨ã®æ—¥æ™‚ã«é–¢é€£ã™ã‚‹æƒ…å ±ã®æä¾›ãŒå¯èƒ½ã§ã™ã€‚
User: ã©ã®ã‚ˆã†ãªãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
# PersonalAssistant: åˆ©ç”¨å¯èƒ½ãªãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã«ã¯æ¬¡ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ï¼šAAAï¼ˆç”°èˆé¢¨ã®é›°å›²æ°—ãŒç‰¹å¾´ã®ã‚¹ãƒ†ãƒ¼ã‚­ãƒã‚¦ã‚¹ï¼‰ã€BBBï¼ˆæµ·ã®æ™¯è‰²ã‚’æ¥½ã—ã‚ã‚‹é­šæ–™ç†ã‚’ä¸­å¿ƒã¨ã—ãŸãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ï¼‰ã€ãŠã‚ˆã³CCCï¼ˆå¤šæ§˜ãªãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’æä¾›ã™ã‚‹ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªé£²é£Ÿåº—ï¼‰ã€‚"
User: ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³AAAã¯ç´ æ•µã§ã™ã­ã€ã‚¹ãƒšã‚·ãƒ£ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
# PersonalAssistant:  "'AAA'ã®ç‰¹åˆ¥ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«ã¤ã„ã¦ãŠçŸ¥ã‚‰ã›ã—ã¾ã™ï¼š\n\n- **ç‰¹è£½ã‚¨ãƒ³ãƒˆãƒªãƒ¼**: Tãƒœãƒ¼ãƒ³ã‚¹ãƒ†ãƒ¼ã‚­\n- **ç‰¹è£½ã‚µãƒ©ãƒ€**: ã‚·ãƒ¼ã‚¶ãƒ¼ã‚µãƒ©ãƒ€\n- **ç‰¹è£½ãƒ‰ãƒªãƒ³ã‚¯**: ã‚ªãƒ¼ãƒ«ãƒ‰ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒ‰\n\nã“ã‚Œã‚‰ã¯Rusticãªé›°å›²æ°—ã‚’æ¥½ã—ã¿ãªãŒã‚‰æ–°é®®ã§ç¾å‘³ã—ã„æ–™ç†ã‚’å‘³ã‚ã†ç†æƒ³çš„ãªé¸æŠè‚¢ã§ã™ã€‚ã•ã‚‰ã«è©³ç´°ã«ã¤ã„ã¦ã”å¸Œæœ›ã§ã—ãŸã‚‰ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚"
User: Tãƒœãƒ¼ãƒ³ã‚¹ãƒ†ãƒ¼ã‚­ ã¯ç¾å‘³ã—ãã†ã€€å€¤æ®µã„ãã‚‰ã§ã™ã‹
# PersonalAssistant: ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³AAAã®Tãƒœãƒ¼ãƒ³ã‚¹ãƒ†ãƒ¼ã‚­ã®å€¤æ®µã¯$9.99ã§ã™ã€‚ç¾å‘³ã—ãã†ã§ã™ã­ï¼äºˆç´„ã‚„ä»–ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã“ã¨ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚
User: ã‚ªãƒ¼ãƒ«ãƒ‰ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã®å€¤æ®µã¯ï¼Ÿ
# PersonalAssistant: ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³AAAã®ã‚ªãƒ¼ãƒ«ãƒ‰ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã®å€¤æ®µã¯$9.99ã§ã™ã€‚ãŠé£²ã¿ç‰©ã‚‚æ¥½ã—ã‚ãã†ã§ã™ã­ï¼ä»–ã«çŸ¥ã‚ŠãŸã„ã“ã¨ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚
User: Tãƒœãƒ¼ãƒ³ã‚¹ãƒ†ãƒ¼ã‚­ã¨ã‚ªãƒ¼ãƒ«ãƒ‰ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã‚’3äººåˆ†é ¼ã¿ãŸã„ã€€åˆè¨ˆé‡‘é¡ã„ãã‚‰ã„ã§ã™ã‹  
# PersonalAssistant: 3äººåˆ†ã®Tãƒœãƒ¼ãƒ³ã‚¹ãƒ†ãƒ¼ã‚­($9.99)ã¨ã‚ªãƒ¼ãƒ«ãƒ‰ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³($9.99)ã‚’æ³¨æ–‡ã—ãŸå ´åˆã®åˆè¨ˆé‡‘é¡ã¯ã€**$59.94**ã§ã™ã€‚ã”æ³¨æ–‡ã‚’æ¤œè¨ã•ã‚Œã¾ã™ã‹ï¼Ÿã¾ãŸã¯äºˆç´„ã®ãŠæ‰‹ä¼ã„ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ
User: ãã‚Œã§æ˜æ—¥ã®20æ™‚ã«äºˆç´„ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
# PersonalAssistant: ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³AAAã§æ˜æ—¥ã®20æ™‚ã«äºˆç´„ãŒç¢ºå®šã—ã¾ã—ãŸã€‚æ¥½ã—ã‚“ã§ãã ã•ã„ï¼ä»–ã«ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚
User: ã‚ã‚ŠãŒã¨ã†
# PersonalAssistant: ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼ç´ æ•µãªæ™‚é–“ã‚’ãŠéã”ã—ãã ã•ã„ã€‚ã¾ãŸä½•ã‹ãŠæ‰‹ä¼ã„ãŒå¿…è¦ãªã¨ãã¯ã„ã¤ã§ã‚‚ãŠå£°ãŒã‘ãã ã•ã„ã­ã€‚ğŸ˜Š
User: exit
"""

if __name__ == "__main__":
    asyncio.run(orchestrator())
